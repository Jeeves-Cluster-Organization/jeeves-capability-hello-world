# Jeeves Hello World - General Chatbot Deployment
#
# 3-service deployment for hello-world chatbot:
#   postgres:      Database for conversation history & state
#   llama-server:  REAL LLM inference (llama.cpp with Qwen 2.5 3B)
#   chatbot:       3-agent pipeline (Understand → Think → Respond) + Chainlit UI
#
# Usage (from project root):
#   Start all services:     docker compose -f docker/docker-compose.hello-world.yml up -d
#   View logs:              docker compose -f docker/docker-compose.hello-world.yml logs -f chatbot
#   Stop services:          docker compose -f docker/docker-compose.hello-world.yml down
#   Open browser:           http://localhost:8000 (Chainlit UI)
#
# Setup (first time):
#   1. Run setup script:    bash docker/setup_hello_world.sh
#   2. Start services:      docker compose -f docker/docker-compose.hello-world.yml up -d
#   3. Wait for health:     docker compose -f docker/docker-compose.hello-world.yml ps
#
# Prerequisites:
#   - Docker and Docker Compose installed
#   - For GPU: nvidia-container-toolkit (Linux) or Docker Desktop with WSL2 (Windows)
#   - At least 4GB RAM available
#   - Optional: Web search API key (Google Custom Search or Serper)

services:
  # ==========================================================================
  # PostgreSQL - Conversation History
  # ==========================================================================
  postgres:
    container_name: chatbot-postgres
    image: pgvector/pgvector:pg16
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: chatbot
      POSTGRES_USER: user
      POSTGRES_PASSWORD: dev_password
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d chatbot"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - chatbot-network

  # ==========================================================================
  # LLM Service - llama.cpp server with Qwen 2.5 3B
  # ==========================================================================
  llama-server:
    container_name: chatbot-llm
    image: ghcr.io/ggerganov/llama.cpp:server-cuda
    ports:
      - "8080:8080"
    volumes:
      - llama-models:/models
    command:
      - --address=0.0.0.0
      - --port=8080
      - --model=/models/qwen2.5-3b-instruct-q4_k_m.gguf
      - --ctx-size=8192
      - --n-gpu-layers=35
      - --parallel=1
      - --threads=4
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    networks:
      - chatbot-network

  # ==========================================================================
  # Chatbot Application - 3-agent pipeline with Chainlit UI
  # ==========================================================================
  chatbot:
    container_name: chatbot-app
    build:
      context: ..
      dockerfile: docker/Dockerfile.hello-world
      args:
        CODE_VERSION: ${CODE_VERSION:-hello-world}
    image: jeeves-hello-world:latest
    ports:
      - "8000:8000"   # Chainlit UI
    environment:
      # Pipeline mode
      - PIPELINE_MODE=general_chatbot

      # Database
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DATABASE=chatbot
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=dev_password

      # REAL LLM configuration
      - LLAMASERVER_HOST=http://llama-server:8080
      - LLM_PROVIDER=llamaserver
      - LLM_TIMEOUT=120

      # Web Search API (optional - set in .env or pass as environment)
      - GOOGLE_API_KEY=${GOOGLE_API_KEY:-}
      - GOOGLE_CX=${GOOGLE_CX:-}
      - SERPER_API_KEY=${SERPER_API_KEY:-}

      # Chainlit Configuration
      - CHAINLIT_HOST=0.0.0.0
      - CHAINLIT_PORT=8000

      # Logging
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=json

    depends_on:
      postgres:
        condition: service_healthy
      llama-server:
        condition: service_healthy

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 30s

    restart: unless-stopped
    networks:
      - chatbot-network

volumes:
  postgres-data:
    driver: local
  llama-models:
    external: true  # Created by setup script with model downloaded

networks:
  chatbot-network:
    driver: bridge

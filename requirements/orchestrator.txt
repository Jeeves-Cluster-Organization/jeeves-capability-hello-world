# ============================================================================
# Orchestrator Requirements - Minimal for llama-server baremetal deployment
# ============================================================================
# Core dependencies for stateful orchestration service with llama-server
#
# OPTIONAL PROVIDERS (install separately if needed):
#   pip install openai      # For OpenAI/Azure providers
#   pip install anthropic   # For Anthropic/Claude provider
#
# OPTIONAL MONITORING:
#   pip install prometheus-client  # Metrics (graceful fallback exists)
#
# See requirements-optional.txt for all optional packages
# ============================================================================

# Include base dependencies
-r base.txt

# Web framework (for compatibility and OpenAPI models)
fastapi==0.109.0
uvicorn[standard]==0.24.0

# Database - PostgreSQL with pgvector
sqlalchemy[asyncio]>=2.0.0,<3.0.0  # Async ORM
asyncpg>=0.29.0  # Async PostgreSQL driver
pgvector>=0.2.0  # pgvector Python client

# Embeddings (L3 Semantic Memory) - REQUIRED for orchestrator
numpy>=1.24.3,<3.0.0
sentence-transformers>=3.0.0,<6.0.0

# NLI (Natural Language Inference) for claim verification
# Per Constitution P1: Anti-hallucination gate in Critic agent
# Note: transformers is already a dependency of sentence-transformers
# but we explicitly include it for NLI model support (cross-encoder/nli-*)
transformers>=4.30.0

# HTTP client for llama-server provider - REQUIRED
httpx==0.27.2

# LiteLLM - unified LLM interface (required by llamaserver_provider)
litellm>=1.30.0

# gRPC tools (for proto compilation at build time)
grpcio-tools>=1.60.0
